---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
torch::torch_manual_seed(1)
```

# torchoptx

<!-- badges: start -->
<!-- badges: end -->

torchoptx provides drop-in replacements for torch optimizers using their C++
implementation directly. Binding directly to the LibTorch implementation has
the performance benefit, as all optimization computations are done in C++.

Here's a small example using `optim_sgd` from `torchoptx`.

```{r sgd, fig.show='animate', fig.height=8, fig.width=8, animation.hook='gifski', aniopts='loop', dpi=96, interval=0.1, out.height='50%', out.width='50%'}
torchopt::test_optim(
    optim = torchoptx::optim_sgd,
    test_fn = "beale",
    opt_hparams = list(),
    steps = 500,
    plot_each_step = TRUE
)
```
And for `optim_adam`:

```{r adam, fig.show='animate', fig.height=8, fig.width=8, animation.hook='gifski', aniopts='loop', dpi=96, interval=0.1, out.height='50%', out.width='50%'}
torchopt::test_optim(
    optim = torchoptx::optim_adam,
    test_fn = "beale",
    opt_hparams = list(),
    steps = 500,
    plot_each_step = TRUE
)
```
